{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\" markdown=\"1\"> Simple Story Generator </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import random\n",
    "import collections\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target log path\n",
    "logs_path = '/tmp/tensorflow/rnn_words'\n",
    "writer = tf.summary.FileWriter(logs_path)\n",
    "\n",
    "# Text file containing words for training\n",
    "training_file ='./data/belling_the_cat_tobecleaned.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Preprocesing Learned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['   % long AGO ,        the mice had a general council to consider what measUres    they could take to outwit their comMon enemy , the cat . some said this , and some said that but   at last a young mouse got up and said he had a proposal to make , which    @ he thought would meet the CaSe . you will all agree £££ , said ^°3 he , that our chief danger consists in the SLY and   treacherous manner in which the enemy approaches   us . now , if we could receive some   signal of her 198@ approach , we could easily    ESCAPE from her . i venture , therefore , to propose     &   that a small bell be procured , and attached BY a   [^?/& ribbon round the neck of the cat . by this means we should always know when she was about , and could easily 12895 retire while she was in the neighbourhood . ThiS    proposal Met with geNeraL    applause , until an old   Mouse got up and said  that is all very well , but who is 55609 to bell the cat ? the mice looked at one   another and nobody spoke . THEN the old mouse said it is easy to propose impossible       reMedies .\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(training_file) as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = [x.strip() for x in content]\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### apply preprocess...\n",
    "training_file ='./data/belling_the_cat.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['long ago , the mice had a general council to consider what measures they could take to outwit their common enemy , the cat . some said this , and some said that but at last a young mouse got up and said he had a proposal to make , which he thought would meet the case . you will all agree , said he , that our chief danger consists in the sly and treacherous manner in which the enemy approaches us . now , if we could receive some signal of her approach , we could easily escape from her . i venture , therefore , to propose that a small bell be procured , and attached by a ribbon round the neck of the cat . by this means we should always know when she was about , and could easily retire while she was in the neighbourhood . this proposal met with general applause , until an old mouse got up and said  that is all very well , but who is to bell the cat ? the mice looked at one another and nobody spoke . then the old mouse said it is easy to propose impossible remedies .\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(training_file) as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **strip()** returns a copy of the string in which all chars have been stripped from the beginning and the end of the string\n",
    "\n",
    "* **split()** returns a list of all the words in the string, using str as the separator (splits on all whitespace if left unspecified), optionally limiting the number of splits to num."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['long ago , the mice had a general council to consider what measures they could take to outwit their common enemy , the cat . some said this , and some said that but at last a young mouse got up and said he had a proposal to make , which he thought would meet the case . you will all agree , said he , that our chief danger consists in the sly and treacherous manner in which the enemy approaches us . now , if we could receive some signal of her approach , we could easily escape from her . i venture , therefore , to propose that a small bell be procured , and attached by a ribbon round the neck of the cat . by this means we should always know when she was about , and could easily retire while she was in the neighbourhood . this proposal met with general applause , until an old mouse got up and said  that is all very well , but who is to bell the cat ? the mice looked at one another and nobody spoke . then the old mouse said it is easy to propose impossible remedies .']\n"
     ]
    }
   ],
   "source": [
    "# strip() removes white spaced and \\n at beggining and end\n",
    "content = [x.strip() for x in content]\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['long' 'ago' ',' 'the' 'mice' 'had' 'a' 'general' 'council' 'to'\n",
      " 'consider' 'what' 'measures' 'they' 'could' 'take' 'to' 'outwit' 'their'\n",
      " 'common' 'enemy' ',' 'the' 'cat' '.' 'some' 'said' 'this' ',' 'and'\n",
      " 'some' 'said' 'that' 'but' 'at' 'last' 'a' 'young' 'mouse' 'got' 'up'\n",
      " 'and' 'said' 'he' 'had' 'a' 'proposal' 'to' 'make' ',' 'which' 'he'\n",
      " 'thought' 'would' 'meet' 'the' 'case' '.' 'you' 'will' 'all' 'agree' ','\n",
      " 'said' 'he' ',' 'that' 'our' 'chief' 'danger' 'consists' 'in' 'the' 'sly'\n",
      " 'and' 'treacherous' 'manner' 'in' 'which' 'the' 'enemy' 'approaches' 'us'\n",
      " '.' 'now' ',' 'if' 'we' 'could' 'receive' 'some' 'signal' 'of' 'her'\n",
      " 'approach' ',' 'we' 'could' 'easily' 'escape' 'from' 'her' '.' 'i'\n",
      " 'venture' ',' 'therefore' ',' 'to' 'propose' 'that' 'a' 'small' 'bell'\n",
      " 'be' 'procured' ',' 'and' 'attached' 'by' 'a' 'ribbon' 'round' 'the'\n",
      " 'neck' 'of' 'the' 'cat' '.' 'by' 'this' 'means' 'we' 'should' 'always'\n",
      " 'know' 'when' 'she' 'was' 'about' ',' 'and' 'could' 'easily' 'retire'\n",
      " 'while' 'she' 'was' 'in' 'the' 'neighbourhood' '.' 'this' 'proposal'\n",
      " 'met' 'with' 'general' 'applause' ',' 'until' 'an' 'old' 'mouse' 'got'\n",
      " 'up' 'and' 'said' 'that' 'is' 'all' 'very' 'well' ',' 'but' 'who' 'is'\n",
      " 'to' 'bell' 'the' 'cat' '?' 'the' 'mice' 'looked' 'at' 'one' 'another'\n",
      " 'and' 'nobody' 'spoke' '.' 'then' 'the' 'old' 'mouse' 'said' 'it' 'is'\n",
      " 'easy' 'to' 'propose' 'impossible' 'remedies' '.']\n",
      "Loaded training data...\n"
     ]
    }
   ],
   "source": [
    "# split content token by token (it returns a list of tokens)\n",
    "content = [word for word in content[0].split()]\n",
    "\n",
    "training_data = np.array(content)\n",
    "print(training_data)\n",
    "print(\"Loaded training data...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vocabulary\n",
    "\n",
    "Each word present in the text will be assigned to a number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ',', 1: 'the', 2: '.', 3: 'and', 4: 'to', 5: 'said', 6: 'a', 7: 'could', 8: 'that', 9: 'cat', 10: 'some', 11: 'this', 12: 'mouse', 13: 'he', 14: 'in', 15: 'we', 16: 'is', 17: 'mice', 18: 'had', 19: 'general', 20: 'enemy', 21: 'but', 22: 'at', 23: 'got', 24: 'up', 25: 'proposal', 26: 'which', 27: 'all', 28: 'of', 29: 'her', 30: 'easily', 31: 'propose', 32: 'bell', 33: 'by', 34: 'she', 35: 'was', 36: 'old', 37: 'long', 38: 'ago', 39: 'council', 40: 'consider', 41: 'what', 42: 'measures', 43: 'they', 44: 'take', 45: 'outwit', 46: 'their', 47: 'common', 48: 'last', 49: 'young', 50: 'make', 51: 'thought', 52: 'would', 53: 'meet', 54: 'case', 55: 'you', 56: 'will', 57: 'agree', 58: 'our', 59: 'chief', 60: 'danger', 61: 'consists', 62: 'sly', 63: 'treacherous', 64: 'manner', 65: 'approaches', 66: 'us', 67: 'now', 68: 'if', 69: 'receive', 70: 'signal', 71: 'approach', 72: 'escape', 73: 'from', 74: 'i', 75: 'venture', 76: 'therefore', 77: 'small', 78: 'be', 79: 'procured', 80: 'attached', 81: 'ribbon', 82: 'round', 83: 'neck', 84: 'means', 85: 'should', 86: 'always', 87: 'know', 88: 'when', 89: 'about', 90: 'retire', 91: 'while', 92: 'neighbourhood', 93: 'met', 94: 'with', 95: 'applause', 96: 'until', 97: 'an', 98: 'very', 99: 'well', 100: 'who', 101: '?', 102: 'looked', 103: 'one', 104: 'another', 105: 'nobody', 106: 'spoke', 107: 'then', 108: 'it', 109: 'easy', 110: 'impossible', 111: 'remedies'}\n"
     ]
    }
   ],
   "source": [
    "# counts from most popular to less popular\n",
    "count = collections.Counter(training_data).most_common()\n",
    "\n",
    "dictionary = dict()\n",
    "for word, _ in count:\n",
    "    dictionary[word] = len(dictionary)\n",
    "reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "\n",
    "vocab_size = len(dictionary)\n",
    "\n",
    "print(reverse_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the input sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offset: 4, end_offset: 4\n"
     ]
    }
   ],
   "source": [
    "n_input = 3\n",
    "offset = random.randint(0, n_input + 1)\n",
    "end_offset = n_input + 1\n",
    "print('offset: %d, end_offset: %d' %(offset, end_offset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words:  [['mice'], ['had'], ['a']]\n",
      "Words in number:  [[17], [18], [6]]\n"
     ]
    }
   ],
   "source": [
    "symbols = [ [str(training_data[i])] for i in range(offset, offset+n_input) ]\n",
    "print('Words: ', symbols)\n",
    "symbols_in_keys = [ [dictionary[ str(training_data[i])]] for i in range(offset, offset+n_input) ]\n",
    "print('Words in number: ', symbols_in_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy array\n",
    "symbols_in_keys = np.array(symbols_in_keys)\n",
    "print('Shape: ', symbols_in_keys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor reshaped:  [[[17]\n",
      "  [18]\n",
      "  [ 6]]]\n",
      "Shape:  (1, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Adding one external dimension\n",
    "symbols_in_keys = np.reshape(symbols_in_keys, [-1, n_input, 1])\n",
    "print('Tensor reshaped: ', symbols_in_keys)\n",
    "print('Shape: ', symbols_in_keys.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding: Set up the label for the input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word:  general\n",
      "Word Number:  19\n"
     ]
    }
   ],
   "source": [
    "print('Word: ', str(training_data[offset+n_input]))\n",
    "print('Word Number: ', dictionary[str(training_data[offset+n_input])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Initialize for one hot encoding\n",
    "symbols_out_onehot = np.zeros([vocab_size], dtype=float)\n",
    "print(symbols_out_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "symbols_out_onehot[dictionary[str(training_data[offset+n_input])]] = 1.0\n",
    "print(symbols_out_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n",
    "print(symbols_out_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 10000\n",
    "display_step = 500\n",
    "n_input = 3\n",
    "\n",
    "# number of units in RNN cell\n",
    "n_hidden = 128 #512\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input, 1])\n",
    "y = tf.placeholder(\"float\", [None, vocab_size])\n",
    "\n",
    "# RNN output node weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([vocab_size]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # reshape to [1, n_input]: from [[38], [0], [1]] to [[38,  0,  1]]\n",
    "    x = tf.reshape(x, [-1, n_input])\n",
    "\n",
    "    # Generate a n_input-element sequence of inputs\n",
    "    # (eg. [had] [a] [general] -> [20] [6] [33])\n",
    "    x = tf.split(x, n_input,1)\n",
    "\n",
    "    # 2-layer LSTM, each layer has n_hidden units.\n",
    "    rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])\n",
    "\n",
    "    # 1-layer LSTM with n_hidden units but with lower accuracy.\n",
    "    # Average Accuracy= 90.60% 50k iter\n",
    "    # Uncomment line below to test but comment out the 2-layer rnn.MultiRNNCell above\n",
    "    # rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
    "\n",
    "    # generate prediction\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # there are n_input outputs but\n",
    "    # we only want the last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = RNN(x, weights, biases)\n",
    "\n",
    "# Loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Model evaluation\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 500, Average Loss= 5.011180, Average Accuracy= 2.60%\n",
      "['old', 'mouse', 'said'] - [it] vs [?]\n",
      "Iter= 1000, Average Loss= 3.758229, Average Accuracy= 6.80%\n",
      "['at', 'one', 'another'] - [and] vs [well]\n",
      "Iter= 1500, Average Loss= 3.018095, Average Accuracy= 12.60%\n",
      "['?', 'the', 'mice'] - [looked] vs [looked]\n",
      "Iter= 2000, Average Loss= 2.761146, Average Accuracy= 24.40%\n",
      "[',', 'but', 'who'] - [is] vs [the]\n",
      "Iter= 2500, Average Loss= 2.382247, Average Accuracy= 36.00%\n",
      "['all', 'very', 'well'] - [,] vs [general]\n",
      "Iter= 3000, Average Loss= 2.391021, Average Accuracy= 35.00%\n",
      "['an', 'old', 'mouse'] - [got] vs [got]\n",
      "Iter= 3500, Average Loss= 2.138273, Average Accuracy= 48.40%\n",
      "['the', 'neighbourhood', '.'] - [this] vs [this]\n",
      "Iter= 4000, Average Loss= 2.258429, Average Accuracy= 44.60%\n",
      "['while', 'she', 'was'] - [in] vs [about]\n",
      "Iter= 4500, Average Loss= 2.250500, Average Accuracy= 46.40%\n",
      "['she', 'was', 'in'] - [the] vs [the]\n",
      "Iter= 5000, Average Loss= 1.934501, Average Accuracy= 50.80%\n",
      "[',', 'and', 'could'] - [easily] vs [said]\n",
      "Iter= 5500, Average Loss= 1.635835, Average Accuracy= 60.80%\n",
      "['about', ',', 'and'] - [could] vs [attached]\n",
      "Iter= 6000, Average Loss= 1.692622, Average Accuracy= 58.60%\n",
      "['neck', 'of', 'the'] - [cat] vs [i]\n",
      "Iter= 6500, Average Loss= 1.515536, Average Accuracy= 63.20%\n",
      "['be', 'procured', ','] - [and] vs [therefore]\n",
      "Iter= 7000, Average Loss= 1.566484, Average Accuracy= 59.80%\n",
      "['be', 'procured', ','] - [and] vs [therefore]\n",
      "Iter= 7500, Average Loss= 1.576191, Average Accuracy= 59.60%\n",
      "[',', 'and', 'attached'] - [by] vs [by]\n",
      "Iter= 8000, Average Loss= 1.255027, Average Accuracy= 64.20%\n",
      "['her', '.', 'i'] - [venture] vs [venture]\n",
      "Iter= 8500, Average Loss= 1.263691, Average Accuracy= 67.20%\n",
      "['easily', 'escape', 'from'] - [her] vs [.]\n",
      "Iter= 9000, Average Loss= 1.147476, Average Accuracy= 71.00%\n",
      "['escape', 'from', 'her'] - [.] vs [mouse]\n",
      "Iter= 9500, Average Loss= 1.046593, Average Accuracy= 72.20%\n",
      "['receive', 'some', 'signal'] - [of] vs [of]\n",
      "Iter= 10000, Average Loss= 1.236312, Average Accuracy= 68.00%\n",
      "['.', 'now', ','] - [if] vs [if]\n",
      "Optimization Finished!\n",
      "Run on command line.\n",
      "\ttensorboard --logdir=/tmp/tensorflow/rnn_words\n",
      "Point your web browser to: http://localhost:6006/\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "step = 0\n",
    "offset = random.randint(0,n_input+1)\n",
    "end_offset = n_input + 1\n",
    "acc_total = 0\n",
    "loss_total = 0\n",
    "\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "while step < training_iters:\n",
    "    # Generate a minibatch. Add some randomness on selection process.\n",
    "    if offset > (len(training_data) - end_offset):\n",
    "        offset = random.randint(0, n_input+1)\n",
    "\n",
    "    symbols_in_keys = [ [dictionary[ str(training_data[i])]] for i in range(offset, offset+n_input) ]\n",
    "    symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "\n",
    "    symbols_out_onehot = np.zeros([vocab_size], dtype=float)\n",
    "    symbols_out_onehot[dictionary[str(training_data[offset+n_input])]] = 1.0\n",
    "    symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n",
    "\n",
    "    _, acc, loss, onehot_pred = sess.run([optimizer, accuracy, cost, pred], \\\n",
    "                                            feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
    "    loss_total += loss\n",
    "    acc_total += acc\n",
    "    if (step+1) % display_step == 0:\n",
    "        print(\"Iter= \" + str(step+1) + \", Average Loss= \" + \\\n",
    "              \"{:.6f}\".format(loss_total/display_step) + \", Average Accuracy= \" + \\\n",
    "              \"{:.2f}%\".format(100*acc_total/display_step))\n",
    "        acc_total = 0\n",
    "        loss_total = 0\n",
    "        symbols_in = [training_data[i] for i in range(offset, offset + n_input)]\n",
    "        symbols_out = training_data[offset + n_input]\n",
    "        symbols_out_pred = reverse_dictionary[int(tf.argmax(onehot_pred, 1).eval(session=sess))]\n",
    "        print(\"%s - [%s] vs [%s]\" % (symbols_in,symbols_out,symbols_out_pred))\n",
    "    step += 1\n",
    "    offset += (n_input+1)\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Run on command line.\")\n",
    "print(\"\\ttensorboard --logdir=%s\" % (logs_path))\n",
    "print(\"Point your web browser to: http://localhost:6006/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['said', 'he', 'had']\n",
      "[5, 13, 18]\n"
     ]
    }
   ],
   "source": [
    "sentence = 'said he had'\n",
    "sentence = sentence.strip()\n",
    "words = sentence.split(' ')\n",
    "print(words)\n",
    "symbols_in_keys = [dictionary[str(words[i])] for i in range(len(words))]\n",
    "print(symbols_in_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 78, 0]\n",
      "[78, 0, 15]\n",
      "[0, 15, 7]\n",
      "[15, 7, 30]\n",
      "[7, 30, 72]\n",
      "[30, 72, 73]\n",
      "[72, 73, 2]\n",
      "[73, 2, 105]\n",
      "[2, 105, 0]\n",
      "[105, 0, 36]\n",
      "[0, 36, 100]\n",
      "[36, 100, 16]\n",
      "[100, 16, 57]\n",
      "[16, 57, 1]\n",
      "[57, 1, 40]\n",
      "[1, 40, 56]\n",
      "[40, 56, 27]\n",
      "[56, 27, 7]\n",
      "[27, 7, 44]\n",
      "[7, 44, 72]\n",
      "[44, 72, 47]\n",
      "[72, 47, 7]\n",
      "[47, 7, 81]\n",
      "[7, 81, 12]\n",
      "[81, 12, 70]\n",
      "[12, 70, 28]\n",
      "[70, 28, 78]\n",
      "[28, 78, 0]\n",
      "[78, 0, 15]\n",
      "[0, 15, 7]\n",
      "[15, 7, 30]\n",
      "[7, 30, 72]\n"
     ]
    }
   ],
   "source": [
    "for i in range(32):\n",
    "    print(symbols_in_keys)\n",
    "    keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "    onehot_pred = sess.run(pred, feed_dict={x: keys})\n",
    "    onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval(session=sess))\n",
    "    sentence = \"%s %s\" % (sentence,reverse_dictionary[onehot_pred_index])\n",
    "    symbols_in_keys = symbols_in_keys[1:]\n",
    "    symbols_in_keys.append(onehot_pred_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "said he had last very meet . and that is a proposal escape from and nobody , old who is agree the consider will all could take escape common could ribbon mouse signal of be , we could easily escape from . nobody , old who is agree the consider will all could take escape common could ribbon mouse signal of be , we could easily escape from\n"
     ]
    }
   ],
   "source": [
    "print(sentence)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
