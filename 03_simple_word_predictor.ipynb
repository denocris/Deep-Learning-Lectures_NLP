{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\" markdown=\"1\"> Simple Story Generator </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import random\n",
    "import collections\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target log path\n",
    "logs_path = '/tmp/tensorflow/rnn_words'\n",
    "writer = tf.summary.FileWriter(logs_path)\n",
    "\n",
    "# Text file containing words for training\n",
    "training_file ='./data/belling_the_cat_tobecleaned.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Preprocesing Learned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['   % long AGO ,        the mice had a general council to consider what measUres    they could take to outwit their comMon enemy , the cat . some said this , and some said that but   at last a young mouse got up and said he had a proposal to make , which    @ he thought would meet the CaSe . you will all agree £££ , said ^°3 he , that our chief danger consists in the SLY and   treacherous manner in which the enemy approaches   us . now , if we could receive some   signal of her 198@ approach , we could easily    ESCAPE from her . i venture , therefore , to propose     &   that a small bell be procured , and attached BY a   [^?/& ribbon round the neck of the cat . by this means we should always know when she was about , and could easily 12895 retire while she was in the neighbourhood . ThiS    proposal Met with geNeraL    applause , until an old   Mouse got up and said  that is all very well , but who is 55609 to bell the cat ? the mice looked at one   another and nobody spoke . THEN the old mouse said it is easy to propose impossible       reMedies .\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(training_file) as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = [x.strip() for x in content]\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose now that we cleaned our text..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### apply preprocess...\n",
    "training_file ='./data/belling_the_cat.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['long ago , the mice had a general council to consider what measures they could take to outwit their common enemy , the cat . some said this , and some said that but at last a young mouse got up and said he had a proposal to make , which he thought would meet the case . you will all agree , said he , that our chief danger consists in the sly and treacherous manner in which the enemy approaches us . now , if we could receive some signal of her approach , we could easily escape from her . i venture , therefore , to propose that a small bell be procured , and attached by a ribbon round the neck of the cat . by this means we should always know when she was about , and could easily retire while she was in the neighbourhood . this proposal met with general applause , until an old mouse got up and said  that is all very well , but who is to bell the cat ? the mice looked at one another and nobody spoke . then the old mouse said it is easy to propose impossible remedies .\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(training_file) as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 'un\\'altra volta'\n",
    "s2 = r'un\\'altra volta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "un'altra volta 14\n"
     ]
    }
   ],
   "source": [
    "print(s1, len(s1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "un\\'altra volta 15\n"
     ]
    }
   ],
   "source": [
    "print(s2, len(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['long ago , the mice had a general council to consider what measures they could take to outwit their common enemy , the cat . some said this , and some said that but at last a young mouse got up and said he had a proposal to make , which he thought would meet the case . you will all agree , said he , that our chief danger consists in the sly and treacherous manner in which the enemy approaches us . now , if we could receive some signal of her approach , we could easily escape from her . i venture , therefore , to propose that a small bell be procured , and attached by a ribbon round the neck of the cat . by this means we should always know when she was about , and could easily retire while she was in the neighbourhood . this proposal met with general applause , until an old mouse got up and said  that is all very well , but who is to bell the cat ? the mice looked at one another and nobody spoke . then the old mouse said it is easy to propose impossible remedies .']\n"
     ]
    }
   ],
   "source": [
    "# strip() removes white spaced and \\n at beggining and end\n",
    "content = [x.strip() for x in content]\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = [ w for w in content[0].split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **strip()** returns a copy of the string in which all chars have been stripped from the beginning and the end of the string\n",
    "\n",
    "* **split()** returns a list of all the words in the string, using str as the separator (splits on all whitespace if left unspecified), optionally limiting the number of splits to num."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['long' 'ago' ',' 'the' 'mice' 'had' 'a' 'general' 'council' 'to'\n",
      " 'consider' 'what' 'measures' 'they' 'could' 'take' 'to' 'outwit' 'their'\n",
      " 'common' 'enemy' ',' 'the' 'cat' '.' 'some' 'said' 'this' ',' 'and'\n",
      " 'some' 'said' 'that' 'but' 'at' 'last' 'a' 'young' 'mouse' 'got' 'up'\n",
      " 'and' 'said' 'he' 'had' 'a' 'proposal' 'to' 'make' ',' 'which' 'he'\n",
      " 'thought' 'would' 'meet' 'the' 'case' '.' 'you' 'will' 'all' 'agree' ','\n",
      " 'said' 'he' ',' 'that' 'our' 'chief' 'danger' 'consists' 'in' 'the' 'sly'\n",
      " 'and' 'treacherous' 'manner' 'in' 'which' 'the' 'enemy' 'approaches' 'us'\n",
      " '.' 'now' ',' 'if' 'we' 'could' 'receive' 'some' 'signal' 'of' 'her'\n",
      " 'approach' ',' 'we' 'could' 'easily' 'escape' 'from' 'her' '.' 'i'\n",
      " 'venture' ',' 'therefore' ',' 'to' 'propose' 'that' 'a' 'small' 'bell'\n",
      " 'be' 'procured' ',' 'and' 'attached' 'by' 'a' 'ribbon' 'round' 'the'\n",
      " 'neck' 'of' 'the' 'cat' '.' 'by' 'this' 'means' 'we' 'should' 'always'\n",
      " 'know' 'when' 'she' 'was' 'about' ',' 'and' 'could' 'easily' 'retire'\n",
      " 'while' 'she' 'was' 'in' 'the' 'neighbourhood' '.' 'this' 'proposal'\n",
      " 'met' 'with' 'general' 'applause' ',' 'until' 'an' 'old' 'mouse' 'got'\n",
      " 'up' 'and' 'said' 'that' 'is' 'all' 'very' 'well' ',' 'but' 'who' 'is'\n",
      " 'to' 'bell' 'the' 'cat' '?' 'the' 'mice' 'looked' 'at' 'one' 'another'\n",
      " 'and' 'nobody' 'spoke' '.' 'then' 'the' 'old' 'mouse' 'said' 'it' 'is'\n",
      " 'easy' 'to' 'propose' 'impossible' 'remedies' '.']\n",
      "Loaded training data...\n"
     ]
    }
   ],
   "source": [
    "# split content token by token (it returns a list of tokens)\n",
    "#content = [word for word in content[0].split()]\n",
    "\n",
    "training_data = np.array(content)\n",
    "\n",
    "print(training_data)\n",
    "print(\"Loaded training data...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vocabulary\n",
    "\n",
    "Each word present in the text will be assigned to a number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc = {',': 0, 'the': 1}\n",
    "cc.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how zip() works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('margarita', 8), ('midori', 12)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cocktails = ['margarita', 'midori']\n",
    "prize = [8, 12]\n",
    "\n",
    "list(zip(cocktails, prize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ',', 1: 'the', 2: '.', 3: 'and', 4: 'to', 5: 'said', 6: 'a', 7: 'could', 8: 'that', 9: 'cat', 10: 'some', 11: 'this', 12: 'mouse', 13: 'he', 14: 'in', 15: 'we', 16: 'is', 17: 'mice', 18: 'had', 19: 'general', 20: 'enemy', 21: 'but', 22: 'at', 23: 'got', 24: 'up', 25: 'proposal', 26: 'which', 27: 'all', 28: 'of', 29: 'her', 30: 'easily', 31: 'propose', 32: 'bell', 33: 'by', 34: 'she', 35: 'was', 36: 'old', 37: 'long', 38: 'ago', 39: 'council', 40: 'consider', 41: 'what', 42: 'measures', 43: 'they', 44: 'take', 45: 'outwit', 46: 'their', 47: 'common', 48: 'last', 49: 'young', 50: 'make', 51: 'thought', 52: 'would', 53: 'meet', 54: 'case', 55: 'you', 56: 'will', 57: 'agree', 58: 'our', 59: 'chief', 60: 'danger', 61: 'consists', 62: 'sly', 63: 'treacherous', 64: 'manner', 65: 'approaches', 66: 'us', 67: 'now', 68: 'if', 69: 'receive', 70: 'signal', 71: 'approach', 72: 'escape', 73: 'from', 74: 'i', 75: 'venture', 76: 'therefore', 77: 'small', 78: 'be', 79: 'procured', 80: 'attached', 81: 'ribbon', 82: 'round', 83: 'neck', 84: 'means', 85: 'should', 86: 'always', 87: 'know', 88: 'when', 89: 'about', 90: 'retire', 91: 'while', 92: 'neighbourhood', 93: 'met', 94: 'with', 95: 'applause', 96: 'until', 97: 'an', 98: 'very', 99: 'well', 100: 'who', 101: '?', 102: 'looked', 103: 'one', 104: 'another', 105: 'nobody', 106: 'spoke', 107: 'then', 108: 'it', 109: 'easy', 110: 'impossible', 111: 'remedies'}\n"
     ]
    }
   ],
   "source": [
    "# counts from most popular to less popular\n",
    "count = collections.Counter(training_data).most_common()\n",
    "\n",
    "dictionary = dict()\n",
    "for word, _ in count:\n",
    "    dictionary[word] = len(dictionary)\n",
    "reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "\n",
    "vocab_size = len(dictionary)\n",
    "\n",
    "print(reverse_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the input sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offset: 3, end_offset: 4\n"
     ]
    }
   ],
   "source": [
    "n_input = 3\n",
    "offset = random.randint(0, n_input + 1)\n",
    "end_offset = n_input + 1\n",
    "print('offset: %d, end_offset: %d' %(offset, end_offset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words:  [['the'], ['mice'], ['had']]\n",
      "Words in number:  [[1], [17], [18]]\n"
     ]
    }
   ],
   "source": [
    "symbols = [ [str(training_data[i])] for i in range(offset, offset+n_input) ]\n",
    "print('Words: ', symbols)\n",
    "symbols_in_keys = [ [dictionary[ str(training_data[i])]] for i in range(offset, offset+n_input) ]\n",
    "print('Words in number: ', symbols_in_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy array\n",
    "symbols_in_keys = np.array(symbols_in_keys)\n",
    "print('Shape: ', symbols_in_keys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor reshaped:  [[[ 1]\n",
      "  [17]\n",
      "  [18]]]\n",
      "Shape:  (1, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Adding one external dimension\n",
    "symbols_in_keys = np.reshape(symbols_in_keys, [-1, n_input, 1])\n",
    "print('Tensor reshaped: ', symbols_in_keys)\n",
    "print('Shape: ', symbols_in_keys.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding: Set up the label for the input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word:  a\n",
      "Word Number:  6\n"
     ]
    }
   ],
   "source": [
    "print('Word: ', str(training_data[offset+n_input]))\n",
    "print('Word Number: ', dictionary[str(training_data[offset+n_input])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Initialize for one hot encoding\n",
    "symbols_out_onehot = np.zeros([vocab_size], dtype=float)\n",
    "print(symbols_out_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "symbols_out_onehot[dictionary[str(training_data[offset+n_input])]] = 1.0\n",
    "print(symbols_out_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n",
    "print(symbols_out_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 50000\n",
    "display_step = 1000\n",
    "n_input = 3\n",
    "\n",
    "# number of units in RNN cell\n",
    "n_hidden = 256 #512\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input, 1])\n",
    "y = tf.placeholder(\"float\", [None, vocab_size])\n",
    "\n",
    "# RNN output node weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([vocab_size]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # reshape to [1, n_input]: from [[38], [0], [1]] to [[38,  0,  1]]\n",
    "    x = tf.reshape(x, [-1, n_input])\n",
    "\n",
    "    # Generate a n_input-element sequence of inputs\n",
    "    # (eg. [had] [a] [general] -> [20] [6] [33])\n",
    "    x = tf.split(x, n_input,1)\n",
    "\n",
    "    # 2-layer LSTM, each layer has n_hidden units.\n",
    "    # rnn_cell = rnn.MultiRNNCell([rnn.BasicLSTMCell(n_hidden),rnn.BasicLSTMCell(n_hidden)])\n",
    "\n",
    "    # 1-layer LSTM with n_hidden units but with lower accuracy.\n",
    "    # Average Accuracy= 90.60% 50k iter\n",
    "    # Uncomment line below to test but comment out the 2-layer rnn.MultiRNNCell above\n",
    "    rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
    "\n",
    "    # generate prediction\n",
    "    outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # there are n_input outputs but\n",
    "    # we only want the last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0218 15:58:44.418830 140312254953280 deprecation.py:323] From <ipython-input-24-670da64a21c3>:16: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "W0218 15:58:44.428677 140312254953280 deprecation.py:323] From <ipython-input-24-670da64a21c3>:19: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "W0218 15:58:44.482217 140312254953280 deprecation.py:506] From /home/dli/dli-lects/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1253: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0218 15:58:44.515450 140312254953280 deprecation.py:506] From /home/dli/dli-lects/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py:734: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0218 15:58:45.144363 140312254953280 deprecation.py:506] From /home/dli/dli-lects/lib/python3.6/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "pred = RNN(x, weights, biases)\n",
    "\n",
    "# Loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred, labels=y))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Model evaluation\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter= 1000, Average Loss= 4.911327, Average Accuracy= 4.10%\n",
      "['and', 'nobody', 'spoke'] - [.] vs [.]\n",
      "Iter= 2000, Average Loss= 3.799532, Average Accuracy= 9.70%\n",
      "[',', 'but', 'who'] - [is] vs [well]\n",
      "Iter= 3000, Average Loss= 3.128400, Average Accuracy= 16.40%\n",
      "['an', 'old', 'mouse'] - [got] vs [got]\n",
      "Iter= 4000, Average Loss= 2.759595, Average Accuracy= 23.70%\n",
      "['could', 'easily', 'retire'] - [while] vs [from]\n",
      "Iter= 5000, Average Loss= 2.039228, Average Accuracy= 38.10%\n",
      "['a', 'ribbon', 'round'] - [the] vs [the]\n",
      "Iter= 6000, Average Loss= 2.229460, Average Accuracy= 40.00%\n",
      "['venture', ',', 'therefore'] - [,] vs [we]\n",
      "Iter= 7000, Average Loss= 1.569134, Average Accuracy= 54.80%\n",
      "['manner', 'in', 'which'] - [the] vs [the]\n",
      "Iter= 8000, Average Loss= 1.673647, Average Accuracy= 53.80%\n",
      "['meet', 'the', 'case'] - [.] vs [.]\n",
      "Iter= 9000, Average Loss= 1.120571, Average Accuracy= 65.90%\n",
      "['and', 'said', 'he'] - [had] vs [all]\n",
      "Iter= 10000, Average Loss= 1.433368, Average Accuracy= 61.60%\n",
      "['and', 'some', 'said'] - [that] vs [that]\n",
      "Iter= 11000, Average Loss= 1.178618, Average Accuracy= 65.90%\n",
      "['to', 'outwit', 'their'] - [common] vs [measures]\n",
      "Iter= 12000, Average Loss= 1.087701, Average Accuracy= 69.80%\n",
      "['a', 'general', 'council'] - [to] vs [to]\n",
      "Iter= 13000, Average Loss= 0.974110, Average Accuracy= 69.40%\n",
      "['old', 'mouse', 'said'] - [it] vs [neighbourhood]\n",
      "Iter= 14000, Average Loss= 0.821864, Average Accuracy= 75.70%\n",
      "['at', 'one', 'another'] - [and] vs [know]\n",
      "Iter= 15000, Average Loss= 0.734324, Average Accuracy= 76.60%\n",
      "['this', 'proposal', 'met'] - [with] vs [with]\n",
      "Iter= 16000, Average Loss= 0.788930, Average Accuracy= 76.10%\n",
      "['could', 'easily', 'retire'] - [while] vs [while]\n",
      "Iter= 17000, Average Loss= 0.766315, Average Accuracy= 75.60%\n",
      "['by', 'this', 'means'] - [we] vs [we]\n",
      "Iter= 18000, Average Loss= 0.645142, Average Accuracy= 79.30%\n",
      "[',', 'to', 'propose'] - [that] vs [that]\n",
      "Iter= 19000, Average Loss= 0.625277, Average Accuracy= 80.10%\n",
      "['receive', 'some', 'signal'] - [of] vs [of]\n",
      "Iter= 20000, Average Loss= 0.630891, Average Accuracy= 81.40%\n",
      "['consists', 'in', 'the'] - [sly] vs [sly]\n",
      "Iter= 21000, Average Loss= 0.551919, Average Accuracy= 83.20%\n",
      "['thought', 'would', 'meet'] - [the] vs [the]\n",
      "Iter= 22000, Average Loss= 0.483260, Average Accuracy= 85.50%\n",
      "['said', 'that', 'but'] - [at] vs [at]\n",
      "Iter= 23000, Average Loss= 0.585833, Average Accuracy= 83.00%\n",
      "['long', 'ago', ','] - [the] vs [the]\n",
      "Iter= 24000, Average Loss= 0.639924, Average Accuracy= 80.20%\n",
      "['and', 'nobody', 'spoke'] - [.] vs [.]\n",
      "Iter= 25000, Average Loss= 0.593125, Average Accuracy= 80.40%\n",
      "['to', 'bell', 'the'] - [cat] vs [cat]\n",
      "Iter= 26000, Average Loss= 0.603768, Average Accuracy= 79.70%\n",
      "['got', 'up', 'and'] - [said] vs [said]\n",
      "Iter= 27000, Average Loss= 0.561640, Average Accuracy= 80.50%\n",
      "['could', 'easily', 'retire'] - [while] vs [while]\n",
      "Iter= 28000, Average Loss= 0.528505, Average Accuracy= 82.70%\n",
      "['attached', 'by', 'a'] - [ribbon] vs [i]\n",
      "Iter= 29000, Average Loss= 0.503385, Average Accuracy= 84.30%\n",
      "[',', 'therefore', ','] - [to] vs [to]\n",
      "Iter= 30000, Average Loss= 0.504079, Average Accuracy= 83.70%\n",
      "['we', 'could', 'easily'] - [escape] vs [escape]\n",
      "Iter= 31000, Average Loss= 0.492312, Average Accuracy= 84.40%\n",
      "['the', 'sly', 'and'] - [treacherous] vs [treacherous]\n",
      "Iter= 32000, Average Loss= 0.503522, Average Accuracy= 83.90%\n",
      "[',', 'said', 'he'] - [,] vs [,]\n",
      "Iter= 33000, Average Loss= 0.422447, Average Accuracy= 86.80%\n",
      "['he', 'thought', 'would'] - [meet] vs [meet]\n",
      "Iter= 34000, Average Loss= 0.505432, Average Accuracy= 84.10%\n",
      "['some', 'said', 'that'] - [but] vs [,]\n",
      "Iter= 35000, Average Loss= 0.426832, Average Accuracy= 87.50%\n",
      "['to', 'outwit', 'their'] - [common] vs [measures]\n",
      "Iter= 36000, Average Loss= 0.461796, Average Accuracy= 86.40%\n",
      "['easy', 'to', 'propose'] - [impossible] vs [impossible]\n",
      "Iter= 37000, Average Loss= 0.308307, Average Accuracy= 88.40%\n",
      "['to', 'bell', 'the'] - [cat] vs [cat]\n",
      "Iter= 38000, Average Loss= 0.442845, Average Accuracy= 85.90%\n",
      "[',', 'but', 'who'] - [is] vs [is]\n",
      "Iter= 39000, Average Loss= 0.369274, Average Accuracy= 88.00%\n",
      "['could', 'easily', 'retire'] - [while] vs [while]\n",
      "Iter= 40000, Average Loss= 0.371067, Average Accuracy= 89.20%\n",
      "['when', 'she', 'was'] - [about] vs [about]\n",
      "Iter= 41000, Average Loss= 0.359507, Average Accuracy= 88.50%\n",
      "['of', 'the', 'cat'] - [.] vs [?]\n",
      "Iter= 42000, Average Loss= 0.395441, Average Accuracy= 88.60%\n",
      "['bell', 'be', 'procured'] - [,] vs [her]\n",
      "Iter= 43000, Average Loss= 0.301080, Average Accuracy= 89.50%\n",
      "['.', 'i', 'venture'] - [,] vs [,]\n",
      "Iter= 44000, Average Loss= 0.476383, Average Accuracy= 85.40%\n",
      "['from', 'her', '.'] - [i] vs [i]\n",
      "Iter= 45000, Average Loss= 0.341032, Average Accuracy= 88.30%\n",
      "['approaches', 'us', '.'] - [now] vs [now]\n",
      "Iter= 46000, Average Loss= 0.436134, Average Accuracy= 88.20%\n",
      "['danger', 'consists', 'in'] - [the] vs [which]\n",
      "Iter= 47000, Average Loss= 0.361533, Average Accuracy= 87.90%\n",
      "['you', 'will', 'all'] - [agree] vs [agree]\n",
      "Iter= 48000, Average Loss= 0.301935, Average Accuracy= 90.40%\n",
      "['a', 'young', 'mouse'] - [got] vs [got]\n",
      "Iter= 49000, Average Loss= 0.380714, Average Accuracy= 87.40%\n",
      "['common', 'enemy', ','] - [the] vs [the]\n",
      "Iter= 50000, Average Loss= 0.360830, Average Accuracy= 88.60%\n",
      "['ago', ',', 'the'] - [mice] vs [mice]\n",
      "Optimization Finished!\n",
      "Run on command line.\n",
      "\ttensorboard --logdir=/tmp/tensorflow/rnn_words\n",
      "Point your web browser to: http://localhost:6006/\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "step = 0\n",
    "offset = random.randint(0,n_input+1)\n",
    "end_offset = n_input + 1\n",
    "acc_total = 0\n",
    "loss_total = 0\n",
    "\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "while step < training_iters:\n",
    "    # Generate a minibatch. Add some randomness on selection process.\n",
    "    if offset > (len(training_data) - end_offset):\n",
    "        offset = random.randint(0, n_input+1)\n",
    "\n",
    "    symbols_in_keys = [ [dictionary[ str(training_data[i])]] for i in range(offset, offset+n_input) ]\n",
    "    symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "\n",
    "    symbols_out_onehot = np.zeros([vocab_size], dtype=float)\n",
    "    symbols_out_onehot[dictionary[str(training_data[offset+n_input])]] = 1.0\n",
    "    symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n",
    "\n",
    "    _, acc, loss, onehot_pred = sess.run([optimizer, accuracy, cost, pred], \\\n",
    "                                            feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
    "    loss_total += loss\n",
    "    acc_total += acc\n",
    "    if (step+1) % display_step == 0:\n",
    "        print(\"Iter= \" + str(step+1) + \", Average Loss= \" + \\\n",
    "              \"{:.6f}\".format(loss_total/display_step) + \", Average Accuracy= \" + \\\n",
    "              \"{:.2f}%\".format(100*acc_total/display_step))\n",
    "        acc_total = 0\n",
    "        loss_total = 0\n",
    "        symbols_in = [training_data[i] for i in range(offset, offset + n_input)]\n",
    "        symbols_out = training_data[offset + n_input]\n",
    "        symbols_out_pred = reverse_dictionary[int(tf.argmax(onehot_pred, 1).eval(session=sess))]\n",
    "        print(\"%s - [%s] vs [%s]\" % (symbols_in,symbols_out,symbols_out_pred))\n",
    "    step += 1\n",
    "    offset += (n_input+1)\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Run on command line.\")\n",
    "print(\"\\ttensorboard --logdir=%s\" % (logs_path))\n",
    "print(\"Point your web browser to: http://localhost:6006/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['said', 'he', 'had']\n",
      "[5, 13, 18]\n"
     ]
    }
   ],
   "source": [
    "sentence = 'said he had'\n",
    "sentence = sentence.strip()\n",
    "words = sentence.split(' ')\n",
    "print(words)\n",
    "symbols_in_keys = [dictionary[str(words[i])] for i in range(len(words))]\n",
    "print(symbols_in_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 13, 18]\n",
      "[13, 18, 6]\n",
      "[18, 6, 25]\n",
      "[6, 25, 4]\n",
      "[25, 4, 50]\n",
      "[4, 50, 0]\n",
      "[50, 0, 26]\n",
      "[0, 26, 13]\n",
      "[26, 13, 51]\n",
      "[13, 51, 52]\n",
      "[51, 52, 53]\n",
      "[52, 53, 1]\n",
      "[53, 1, 54]\n",
      "[1, 54, 2]\n",
      "[54, 2, 55]\n",
      "[2, 55, 56]\n",
      "[55, 56, 27]\n",
      "[56, 27, 57]\n",
      "[27, 57, 0]\n",
      "[57, 0, 5]\n",
      "[0, 5, 13]\n",
      "[5, 13, 0]\n",
      "[13, 0, 8]\n",
      "[0, 8, 58]\n",
      "[8, 58, 59]\n",
      "[58, 59, 60]\n",
      "[59, 60, 14]\n",
      "[60, 14, 1]\n",
      "[14, 1, 62]\n",
      "[1, 62, 3]\n",
      "[62, 3, 63]\n",
      "[3, 63, 64]\n"
     ]
    }
   ],
   "source": [
    "for i in range(32):\n",
    "    print(symbols_in_keys)\n",
    "    keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
    "    onehot_pred = sess.run(pred, feed_dict={x: keys})\n",
    "    onehot_pred_index = int(tf.argmax(onehot_pred, 1).eval(session=sess))\n",
    "    sentence = \"%s %s\" % (sentence,reverse_dictionary[onehot_pred_index])\n",
    "    symbols_in_keys = symbols_in_keys[1:]\n",
    "    symbols_in_keys.append(onehot_pred_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "said he had a proposal to make , which he thought would meet the case . you will all agree , said he , that our chief danger in the sly and treacherous manner in\n"
     ]
    }
   ],
   "source": [
    "print(sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

