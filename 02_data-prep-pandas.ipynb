{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\" markdown=\"1\"> Generate a Dataset with Pandas </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re\n",
    "\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH='/home/asr/prj_SlotTagger/dnn_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH=os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus_six_num: 103484, Corpus_six_ver: 285704, Ratio: 0.362\n",
      "CPU times: user 137 ms, sys: 12.8 ms, total: 150 ms\n",
      "Wall time: 154 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_lines_num  = sum(1 for line in open(ROOT_PATH + '/data/sei_6/num/sei_num'))\n",
    "num_lines_ver  = sum(1 for line in open(ROOT_PATH + '/data/sei_6/ver/sei_verb'))\n",
    "\n",
    "ratio = num_lines_num  / float(num_lines_ver) \n",
    "print('Corpus_six_num: %d, Corpus_six_ver: %d, Ratio: %0.3f' %(num_lines_num, num_lines_ver, ratio)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Data-Frame (Balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(directory_1, directory_2):\n",
    "    # NOTE: Put in directory_2 the largest corpus\n",
    "    data = {}\n",
    "    data[\"sentence\"] = []\n",
    "    data[\"class\"] = []\n",
    "    l1 = 0\n",
    "    for file_path in os.listdir(directory_1):\n",
    "        with tf.gfile.GFile(os.path.join(directory_1 , file_path), \"rb\") as f:\n",
    "                # strip() removes white spaces before and after the string\n",
    "                # decode() converst a byte object ('b) in a python3 string\n",
    "                list_of_sentences = [s.strip().decode() for s in f.readlines()]\n",
    "                num_rows_1 = len(list_of_sentences)\n",
    "                for i in range(num_rows_1):\n",
    "                    data[\"sentence\"].append(list_of_sentences[i])\n",
    "                    data[\"class\"].append(1)\n",
    "    \n",
    "    for file_path in os.listdir(directory_2):\n",
    "        with tf.gfile.GFile(os.path.join(directory_2 , file_path), \"rb\") as f:\n",
    "                # strip() removes white spaces before and after the string\n",
    "                # decode() converst a byte object ('b) in a python3 string\n",
    "                list_of_sentences = [s.strip().decode() for s in f.readlines() if np.random.random() <= ratio]\n",
    "                num_rows_1 = len(list_of_sentences)\n",
    "                for i in range(num_rows_1):\n",
    "                    data[\"sentence\"].append(list_of_sentences[i])\n",
    "                    data[\"class\"].append(0)\n",
    "\n",
    "    return pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.12 s, sys: 97.2 ms, total: 2.21 s\n",
      "Wall time: 2.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "directory_1 = ROOT_PATH + '/data/sei_6/num/'\n",
    "directory_2 = ROOT_PATH + '/data/sei_6/ver/'\n",
    "\n",
    "dataset_df = load_dataset(directory_1, directory_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence\n",
       "class          \n",
       "0        103697\n",
       "1        103484"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Balanced\n",
    "dataset_df.groupby('class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a al comma dopo le parole inferiore a sei\n",
      "whoa whoa whoa sei cifre\n",
      "a anni accoltellò all'addome jimmy davis un bambino di sei anni e lo nascose nei\n",
      "usati in un codice con sei cifre\n",
      "a anni da del mondo e con l'uscita al primo turno da sei slam\n",
      "tuttavia sono sei cifre\n",
      "a anni e sei mesi dalla\n",
      "si dispone di un reddito di sei cifre\n",
      "a anni passa nelle giovanili del milan dove trascorre sei stagioni laureandosi per due volte\n",
      "sei cifre solo per cominciare\n",
      "a a sei\n",
      "sei cifre quello che mi serve\n",
      "a a sei minuti dal\n",
      "sei cifre non mi serviva altro\n",
      "aa vv sei secoli di musica nel duomo\n",
      "sei cifre facili\n",
      "a balaustra e sei gruppi di scalini che su ambedue i lati conducono verso la città\n",
      "sei cifre come il codice a barre che potrebbe essere l algoritmo magico\n",
      "a baltimora nel maryland il più giovane di sei figli\n",
      "secondo sotto la mia gestione ogni accordo che supera le sei cifre deve essere solennemente commemorato\n"
     ]
    }
   ],
   "source": [
    "# Print some samples\n",
    "for i in range(10):\n",
    "    print(dataset_df.iloc[i]['sentence'])\n",
    "    print(dataset_df.iloc[-i -1]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a al comma dopo le parole inferiore a sei</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a anni accoltellò all'addome jimmy davis un ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a anni da del mondo e con l'uscita al primo tu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a anni e sei mesi dalla</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a anni passa nelle giovanili del milan dove tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  class\n",
       "0          a al comma dopo le parole inferiore a sei      1\n",
       "1  a anni accoltellò all'addome jimmy davis un ba...      1\n",
       "2  a anni da del mondo e con l'uscita al primo tu...      1\n",
       "3                            a anni e sei mesi dalla      1\n",
       "4  a anni passa nelle giovanili del milan dove tr...      1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207176</th>\n",
       "      <td>sei cifre solo per cominciare</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207177</th>\n",
       "      <td>si dispone di un reddito di sei cifre</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207178</th>\n",
       "      <td>tuttavia sono sei cifre</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207179</th>\n",
       "      <td>usati in un codice con sei cifre</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207180</th>\n",
       "      <td>whoa whoa whoa sei cifre</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     sentence  class\n",
       "207176          sei cifre solo per cominciare      0\n",
       "207177  si dispone di un reddito di sei cifre      0\n",
       "207178                tuttavia sono sei cifre      0\n",
       "207179       usati in un codice con sei cifre      0\n",
       "207180               whoa whoa whoa sei cifre      0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    8.396056\n",
       "class       1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting number of words and mean\n",
    "dataset_df.astype('str').applymap(lambda x: str(x).count(' ') + 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    22\n",
       "class        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max length sentence\n",
    "dataset_df.astype('str').applymap(lambda x: str(x).count(' ') + 1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    3.600541\n",
       "class       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max length sentence\n",
    "dataset_df.astype('str').applymap(lambda x: str(x).count(' ') + 1).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1294829e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram of the lengths\n",
    "%matplotlib inline\n",
    "\n",
    "length_sentence = dataset_df.astype('str').applymap(lambda x: str(x).count(' ') + 1)\n",
    "plt.hist(length_sentence['sentence'],bins=range(50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non hai una vacanza da sei anni cal andiamo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mi ricordi i miei impegni del sei agosto prossimo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ti sei ehm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dice di aspettarlo alla stazione stasera alle sei</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accoppiato un cambio automatico a sei</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nei primi sei mesi di quest'anno sbb cff ffs c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>da quando sei tornata in scozia hai cercato di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dai trent tu sei meglio di così</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>di sei mesi del</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>se ogni sei mesi il ministro delle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  class\n",
       "0        non hai una vacanza da sei anni cal andiamo      1\n",
       "1  mi ricordi i miei impegni del sei agosto prossimo      1\n",
       "2                                         ti sei ehm      0\n",
       "3  dice di aspettarlo alla stazione stasera alle sei      1\n",
       "4              accoppiato un cambio automatico a sei      1\n",
       "5  nei primi sei mesi di quest'anno sbb cff ffs c...      1\n",
       "6  da quando sei tornata in scozia hai cercato di...      0\n",
       "7                    dai trent tu sei meglio di così      0\n",
       "8                                    di sei mesi del      1\n",
       "9                 se ogni sei mesi il ministro delle      1"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = [i for i in range(dataset_df.shape[0])]\n",
    "random.shuffle(index)\n",
    "dataset = dataset_df.set_index([index]).sort_index()\n",
    "\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some other cleaning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>non hai una vacanza da sei anni cal andiamo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mi ricordi i miei impegni del sei agosto prossimo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ti sei ehm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dice di aspettarlo alla stazione stasera alle sei</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accoppiato un cambio automatico a sei</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nei primi sei mesi di quest anno sbb cff ffs c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>da quando sei tornata in scozia hai cercato di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dai trent tu sei meglio di così</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>di sei mesi del</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>se ogni sei mesi il ministro delle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  class\n",
       "0        non hai una vacanza da sei anni cal andiamo      1\n",
       "1  mi ricordi i miei impegni del sei agosto prossimo      1\n",
       "2                                         ti sei ehm      0\n",
       "3  dice di aspettarlo alla stazione stasera alle sei      1\n",
       "4              accoppiato un cambio automatico a sei      1\n",
       "5  nei primi sei mesi di quest anno sbb cff ffs c...      1\n",
       "6  da quando sei tornata in scozia hai cercato di...      0\n",
       "7                    dai trent tu sei meglio di così      0\n",
       "8                                    di sei mesi del      1\n",
       "9                 se ogni sei mesi il ministro delle      1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude1 = ['\\t', '\"', '?'] # list\n",
    "exclude2 = [\"'\", \"  \", \"   \", \"    \", \"     \"] # list\n",
    "\n",
    "def clean_text(text):\n",
    "    for c in exclude1:\n",
    "        text=text.replace(c,'')\n",
    "    for c in exclude2:\n",
    "        text=text.replace(c, \" \")\n",
    "    return text.lower().strip()\n",
    "\n",
    "sentence_processed = list(map(clean_text, dataset['sentence'].values))\n",
    "\n",
    "dataset['sentence'] = sentence_processed\n",
    "\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.6 s, sys: 3.34 s, total: 26 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "def lemmatizer(text):\n",
    "    doc = nlp(text)\n",
    "    lemmatizer = [token.lemma_ for token in doc]\n",
    "    return ' '.join(lemmatizer)\n",
    "\n",
    "sentence_processed = list(map(lemmatizer, dataset['sentence'].head(1000).values))\n",
    "\n",
    "#dataset['sentence'] = sentence_processed\n",
    "\n",
    "#dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.333333333333336"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(200000/1000)*13.3 / 60.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split for Tagger Classifier (Train, Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-Set size: 176064\n",
      "Validation-Set size: 31071\n"
     ]
    }
   ],
   "source": [
    "\n",
    "splitter =  model_selection.StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=19850610)\n",
    "\n",
    "splits = list(splitter.split(X=dataset['sentence'], y=dataset['class']))\n",
    "train_index = splits[0][0]\n",
    "valid_index = splits[0][1]\n",
    "\n",
    "train_df = dataset.loc[train_index,:]\n",
    "print('Training-Set size: %d' %len(train_df))\n",
    "\n",
    "valid_df = dataset.loc[valid_index,:]\n",
    "print('Validation-Set size: %d' %len(valid_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "0    88103\n",
      "1    87961\n",
      "Name: class, dtype: int64\n",
      "class 0 %: 50.04\n",
      "class 1 %: 49.96\n",
      "\n",
      "Validation Set\n",
      "0    15548\n",
      "1    15523\n",
      "Name: class, dtype: int64\n",
      "class 0 %: 50.04\n",
      "class 1 %: 49.96\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set\")\n",
    "training_value_counts = train_df['class'].value_counts()\n",
    "print(training_value_counts)\n",
    "print(\"class 0 %: {}\".format(round(training_value_counts[0]/len(train_df)*100,2)))\n",
    "print(\"class 1 %: {}\".format(round(training_value_counts[1]/len(train_df)*100,2)))\n",
    "print(\"\")\n",
    "print(\"Validation Set\")\n",
    "validation_value_counts = valid_df['class'].value_counts()\n",
    "print(validation_value_counts)\n",
    "print(\"class 0 %: {}\".format(round(validation_value_counts[0]/len(valid_df)*100,2)))\n",
    "print(\"class 1 %: {}\".format(round(validation_value_counts[1]/len(valid_df)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(os.path.join(ROOT_PATH, 'tsvfiles/train_data.tsv'), header=False, index=False, sep='\\t')\n",
    "valid_df.to_csv(os.path.join(ROOT_PATH, 'tsvfiles/valid_data.tsv'), header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Vocabulary and Save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = get_stop_words('italian') + get_stop_words('english')\n",
    "\n",
    "my_stop_words = []\n",
    "for my_word in my_stop_words:\n",
    "    stop_words.append(my_word)\n",
    "    \n",
    "# Important step for this dataset!!!!\n",
    "stop_words.remove('sei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['criks', '16', '9', 'cv', 'ai']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ww = ['criks', 'crjis3','cr456is', '45crist','1v','f4','16','l','9','5ffff56566778','cv', 'ai']\n",
    "\n",
    "falseIfDigit = lambda word: not bool((re.match('^(?=.*[0-9])', str(word))))\n",
    "\n",
    "[w for w in ww if (falseIfDigit(w) or w.isdigit()) and (len(w) > 1 or w.isdigit()) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function returns FALSE if there is a digit in the string (i.e '4mmm', 'm44m', 'llp4')\n",
    "#falseIfDigit = lambda word: not bool((re.match('^(?=.*[0-9])', str(word))))\n",
    "\n",
    "def get_vocab():\n",
    "    #allWords = []\n",
    "    vocab = set()\n",
    "    for text in train_df['sentence'].values:\n",
    "        words = text.split(' ')\n",
    "        # remove digits\n",
    "        words_only = [w for w in words if not w.isdigit()]\n",
    "        # exclude words shorter than 2, but not numbers. exclude words with numbers inside, i.e. '3cris', 'c45ris', 'cris23'\n",
    "        #words_ = [w for w in words_only if (falseIfDigit(w) or w.isdigit()) and (len(w) > 1 or w.isdigit()) ]\n",
    "        words_ = [w for w in words_only if len(w) > 0 ]\n",
    "        #words_ = words_only\n",
    "        #allWords = allWords + words_\n",
    "        word_set = set(words_)\n",
    "        vocab.update(word_set)\n",
    "    \n",
    "    #vocab.remove('')\n",
    "    return list(vocab)#, allWords\n",
    "\n",
    "def get_all_words():\n",
    "    allWords = []\n",
    "    cnt = 0\n",
    "    for text in train_df['sentence'].values:\n",
    "        words = text.split(' ')\n",
    "        # remove digits\n",
    "        words_only = [w for w in words if not w.isdigit()]\n",
    "        # exclude words shorter than 2, but not numbers. exclude words with numbers inside, i.e. '3cris', 'c45ris', 'cris23'\n",
    "        #words_ = [w for w in words_only if (falseIfDigit(w) or w.isdigit()) and (len(w) > 1 or w.isdigit()) ]\n",
    "        words_ = [w for w in words_only if len(w) > 0 ]\n",
    "        #words_ = words_only\n",
    "        allWords = allWords + words_\n",
    "        #word_set = set(words_)\n",
    "        cnt += 1\n",
    "        if cnt%10000==0:\n",
    "            print('-----------', cnt)\n",
    "    \n",
    "    return allWords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- 64006\n",
      "CPU times: user 820 ms, sys: 2 µs, total: 820 ms\n",
      "Wall time: 820 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vocab = get_vocab()\n",
    "print('--------------------', len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ci' in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 10000\n",
      "----------- 20000\n",
      "----------- 30000\n",
      "----------- 40000\n",
      "----------- 50000\n",
      "----------- 60000\n",
      "----------- 70000\n",
      "----------- 80000\n",
      "----------- 90000\n",
      "----------- 100000\n",
      "----------- 110000\n",
      "----------- 120000\n",
      "----------- 130000\n",
      "----------- 140000\n",
      "----------- 150000\n",
      "----------- 160000\n",
      "----------- 170000\n",
      "-------------------- 1522514\n",
      "CPU times: user 44min 42s, sys: 596 ms, total: 44min 43s\n",
      "Wall time: 44min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "allWords = get_all_words()\n",
    "print('--------------------', len(allWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cnt_allWords = Counter(allWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_words_sorted_by_appearence = sorted(cnt_allWords.items(), key=lambda kv: len(vocab) - kv[1])\n",
    "#vocab_words_sorted_by_appearence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_words_sorted_by_appearence_list = [word[0] for word in vocab_words_sorted_by_appearence]\n",
    "#vocab_words_sorted_by_appearence_list, len(vocab_words_sorted_by_appearence_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ci' in vocab_words_sorted_by_appearence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64006\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "STOP_WORDS = False\n",
    "REDUCED_SIZE_VOC = True\n",
    "SIZE_VOC = 25000\n",
    "\n",
    "vocab = vocab_words_sorted_by_appearence_list\n",
    "\n",
    "if STOP_WORDS:\n",
    "    vocab = [w for w in vocab if w not in stop_words]\n",
    "    words_and_frequence = [ (word, freq) for (word, freq) in vocab_words_sorted_by_appearence if word not in stop_words]\n",
    "\n",
    "print(len(vocab))\n",
    "if REDUCED_SIZE_VOC:\n",
    "    vocab = vocab[0:SIZE_VOC]\n",
    "print(len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ci' in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'abbiamo' in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_WORD = '#=KS=#'\n",
    "\n",
    "PATH_VOC = os.path.join(ROOT_PATH, 'tsvfiles/vocab_5k.tsv')\n",
    "with open(PATH_VOC , 'w') as file:\n",
    "#with open('/home/asr/Data/classif_task/jsgf_data/vocab_list.tsv', 'w') as file:\n",
    "    file.write(\"{}\\n\".format(PAD_WORD))\n",
    "    for word in vocab:\n",
    "        file.write(\"{}\\n\".format(word))\n",
    "        \n",
    "PATH_WORDS = os.path.join(ROOT_PATH, 'tsvfiles/n_words_5k.tsv')        \n",
    "with open(PATH_WORDS, 'w') as file:\n",
    "#with open('/home/asr/Data/classif_task/jsgf_data/n_words.tsv', 'w') as file:\n",
    "    file.write(str(len(vocab)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
